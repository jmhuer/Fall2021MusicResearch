{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPA5H9Bmv9dLCO+nAYk7aw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmhuer/Fall2021MusicResearch/blob/main/tensorflow_AEwHT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XGBgZ1gkyUdp",
        "outputId": "314a8c86-025f-46ce-874b-8aedcefc0381"
      },
      "source": [
        "!pip install pretty_midi\n",
        "!git clone https://github.com/jmhuer/ModularSparseAutoencoder\n",
        "!git clone https://github.com/music-x-lab/POP909-Dataset\n",
        "!git clone https://github.com/jmhuer/HT\n",
        "!git clone https://github.com/Tsung-Ping/functional-harmony\n",
        "# %cd /content/POP909-Dataset/data_process\n",
        "!pip install libfmp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 14.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.19.5)\n",
            "Collecting mido>=1.1.16\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.15.0)\n",
            "Building wheels for collected packages: pretty-midi\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591953 sha256=32632db718e31d03f0bf306c178196d0b300325985af96780417cef97bc53b76\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/74/7c/a06473ca8dcb63efb98c1e67667ce39d52100f837835ea18fa\n",
            "Successfully built pretty-midi\n",
            "Installing collected packages: mido, pretty-midi\n",
            "Successfully installed mido-1.2.10 pretty-midi-0.2.9\n",
            "Cloning into 'ModularSparseAutoencoder'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 28 (delta 12), reused 10 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), done.\n",
            "Cloning into 'POP909-Dataset'...\n",
            "remote: Enumerating objects: 9265, done.\u001b[K\n",
            "remote: Counting objects: 100% (9265/9265), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8157/8157), done.\u001b[K\n",
            "remote: Total 9265 (delta 13), reused 9245 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (9265/9265), 45.75 MiB | 28.31 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "Cloning into 'HT'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 29 (delta 12), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n",
            "Cloning into 'functional-harmony'...\n",
            "remote: Enumerating objects: 460, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 460 (delta 13), reused 49 (delta 12), pack-reused 396\u001b[K\n",
            "Receiving objects: 100% (460/460), 2.50 MiB | 1.12 MiB/s, done.\n",
            "Resolving deltas: 100% (202/202), done.\n",
            "Collecting libfmp\n",
            "  Downloading libfmp-1.2.1-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 15.4 MB/s \n",
            "\u001b[?25hCollecting pysoundfile<1.0.0,>=0.9.0\n",
            "  Downloading PySoundFile-0.9.0.post1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from libfmp) (1.19.5)\n",
            "Collecting ipython<8.0.0,>=7.8.0\n",
            "  Downloading ipython-7.28.0-py3-none-any.whl (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib<4.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from libfmp) (3.2.2)\n",
            "Requirement already satisfied: numba<1.0.0,>=0.51.0 in /usr/local/lib/python3.7/dist-packages (from libfmp) (0.51.2)\n",
            "Requirement already satisfied: pretty-midi<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from libfmp) (0.2.9)\n",
            "Requirement already satisfied: librosa<1.0.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from libfmp) (0.8.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from libfmp) (1.4.1)\n",
            "Collecting music21<6.0.0,>=5.7.0\n",
            "  Downloading music21-5.7.2.tar.gz (18.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.5 MB 336 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from libfmp) (1.1.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8.0.0,>=7.8.0->libfmp) (2.6.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0.0,>=7.8.0->libfmp) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0.0,>=7.8.0->libfmp) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8.0.0,>=7.8.0->libfmp) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0.0,>=7.8.0->libfmp) (5.1.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython<8.0.0,>=7.8.0->libfmp) (0.1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8.0.0,>=7.8.0->libfmp) (0.7.5)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.20-py3-none-any.whl (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8.0.0,>=7.8.0->libfmp) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0.0,>=7.8.0->libfmp) (0.18.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8.0.0,>=7.8.0->libfmp) (0.8.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa<1.0.0,>=0.8.0->libfmp) (1.5.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa<1.0.0,>=0.8.0->libfmp) (1.0.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa<1.0.0,>=0.8.0->libfmp) (0.10.3.post1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa<1.0.0,>=0.8.0->libfmp) (0.22.2.post1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa<1.0.0,>=0.8.0->libfmp) (21.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<1.0.0,>=0.8.0->libfmp) (2.1.9)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa<1.0.0,>=0.8.0->libfmp) (0.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.1.0->libfmp) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.1.0->libfmp) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.1.0->libfmp) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.1.0->libfmp) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib<4.0.0,>=3.1.0->libfmp) (1.15.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba<1.0.0,>=0.51.0->libfmp) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->libfmp) (2018.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython<8.0.0,>=7.8.0->libfmp) (0.7.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<1.0.0,>=0.8.0->libfmp) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<1.0.0,>=0.8.0->libfmp) (2.23.0)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty-midi<1.0.0,>=0.2.0->libfmp) (1.2.10)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.8.0->libfmp) (0.2.5)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.7/dist-packages (from pysoundfile<1.0.0,>=0.9.0->libfmp) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=0.6->pysoundfile<1.0.0,>=0.9.0->libfmp) (2.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<1.0.0,>=0.8.0->libfmp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<1.0.0,>=0.8.0->libfmp) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<1.0.0,>=0.8.0->libfmp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<1.0.0,>=0.8.0->libfmp) (2.10)\n",
            "Building wheels for collected packages: music21\n",
            "  Building wheel for music21 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for music21: filename=music21-5.7.2-py3-none-any.whl size=22024624 sha256=8d1480acdaf4d9291d5d7672b58fc52e0f34524915a675967c40d275ca10db78\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/cb/ae/fd264ebf1e9cf01c15576ee4c128f1bfd907a120c0a7a5b542\n",
            "Successfully built music21\n",
            "Installing collected packages: prompt-toolkit, pysoundfile, music21, ipython, libfmp\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: music21\n",
            "    Found existing installation: music21 5.5.0\n",
            "    Uninstalling music21-5.5.0:\n",
            "      Successfully uninstalled music21-5.5.0\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.20 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.28.0 which is incompatible.\u001b[0m\n",
            "Successfully installed ipython-7.28.0 libfmp-1.2.1 music21-5.7.2 prompt-toolkit-3.0.20 pysoundfile-0.9.0.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km3TD1zn3j3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d439dbf-3dbf-43df-d851-92c4529247bc"
      },
      "source": [
        "from HT.BPS_FH_preprocessing import main\n",
        "\n",
        "main()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message: load note data ...\n",
            "lowest pitch = 24 highest pitch =  101\n",
            "Message: load chord labels...\n",
            "Message: get framewise labels ...\n",
            "max_length = 8482\n",
            "min_length = 872\n",
            "keys in corpus['op'] = dict_keys(['pianoroll', 'chromagram', 'start_time', 'label'])\n",
            "label fields =  [('op', '<U10'), ('onset', '<f8'), ('key', '<U10'), ('degree1', '<U10'), ('degree2', '<U10'), ('quality', '<U10'), ('inversion', '<i8'), ('rchord', '<U10'), ('root', '<U10'), ('tquality', '<U10'), ('chord_change', '<i8')]\n",
            "Running Message: augment data...\n",
            "keys in corpus_aug['shift_id']['op'] = dict_keys(['pianoroll', 'tonal_centroid', 'start_time', 'label'])\n",
            "Running Message: reshape data...\n",
            "keys in corpus_aug_reshape['shift_id']['op'] = dict_keys(['pianoroll', 'tonal_centroid', 'start_time', 'label', 'len'])\n",
            "sequence_len_non_overlaped = [17, 22, 23, 24, 30, 34, 36, 40, 44, 48, 52, 53, 66, 72, 80, 84, 86, 88, 100, 102, 104, 116, 118, 120, 128]\n",
            "sequence_len_overlaped = [17, 22, 23, 24, 30, 34, 36, 40, 44, 48, 52, 53, 66, 72, 80, 84, 86, 88, 100, 102, 104, 116, 118, 120, 128]\n",
            "Preprocessed data saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdRQ7nWU1zIZ",
        "outputId": "1a081a1d-eef4-487e-bb53-ef5e2b2b0fee"
      },
      "source": [
        "# !pip install tensorflow-gpu==1.15\n",
        "from HT.chord_symbol_recognition_ae import train_HT\n",
        "from collections import Counter, namedtuple\n",
        "from HT.BPS_FH_preprocessing import main\n",
        "from HT.chord_symbol_recognition_ae import load_data_symbol\n",
        "#\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "# import utils\n",
        "import pretty_midi \n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "##only tensor transforms\n",
        "\n",
        "datasetpath = '/content/'\n",
        "\n",
        "train_data, test_data = load_data_symbol(dir=datasetpath + 'BPS_FH_preprocessed_data_MIREX_Mm.pickle', test_set_id=1, sequence_with_overlap=True)\n",
        "print(\"load_data_symbol train_data size: {}\".format(train_data[\"tchord\"].shape))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiZ74DNGYD4j"
      },
      "source": [
        "##Need val batch to match train batch size for autoencoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ErLyaAuRFLY"
      },
      "source": [
        "# train_data2 = {}\n",
        "test_data2 = {}\n",
        "# train_data2['label'] = {}\n",
        "test_data2['label'] = {}\n",
        "n = 40  # for 2 random indices\n",
        "index = np.random.choice(test_data[\"tchord\"].shape[0], n, replace=False)\n",
        "            \n",
        "test_data2['label']['chord_change'] =  test_data['label']['chord_change'][index]\n",
        "test_data2[\"pianoroll\"] =  test_data['pianoroll'][index]\n",
        "test_data2[\"tchord\"] =  test_data['tchord'][index]\n",
        "test_data2[\"root\"] =  test_data['root'][index]\n",
        "test_data2[\"len\"] =  test_data['len'][index]\n",
        "test_data2[\"tquality\"] = test_data['tquality'][index]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4sxr8oNYOZe"
      },
      "source": [
        "#Here is the Linear autoencoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yULLsZoeq6eV"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "import random\n",
        "\n",
        "class autoencoder:\n",
        "    def __init__(self):\n",
        "        self.weights = {\n",
        "            'encoder_h1': tf.Variable(tf.random_normal([88, 20])/100),\n",
        "            'encoder_h2': tf.Variable(tf.random_normal([4000, 1000])/100),\n",
        "            'decoder_h1': tf.Variable(tf.random_normal([1000, 2000])/100),\n",
        "            'decoder_h2': tf.Variable(tf.random_normal([20, 88])/100)\n",
        "        }\n",
        "        self.biases = {\n",
        "            'encoder_b1': tf.Variable(tf.random_normal([1000])),\n",
        "            'decoder_b1': tf.Variable(tf.random_normal([11264]))\n",
        "        }\n",
        "        # Building the encoder\n",
        "    def encoder(self, x):\n",
        "        # Encoder Hidden layer with sigmoid activation #1\n",
        "        layer_1 = tf.nn.relu(tf.matmul(x, self.weights['encoder_h1']))\n",
        "        return layer_1\n",
        "    # Building the decoder\n",
        "    def decoder(self, x):\n",
        "        layer_2 = tf.nn.relu(tf.matmul(x, self.weights['decoder_h2']))\n",
        "        return layer_2\n",
        "    def code(self, x, k):\n",
        "        # do =  x[0,:,:]\n",
        "        # x = tf.layers.flatten(x)\n",
        "        encoder_op = self.encoder(x)\n",
        "        print(encoder_op.shape)\n",
        "        # values, indices  =  = tf.math.top_k(encoder_op, k=k)\n",
        "        # gathered_values = tf.gather(input, indices, batch_dims=-1)\n",
        "        decoder_op = self.decoder(encoder_op)\n",
        "        # x = tf.zeros((40, 128,88))\n",
        "        # decoder_op = tf.placeholder_with_default(decoder_op,[None, 128, 88])\n",
        "        return decoder_op\n",
        "\n",
        "\n",
        "ae = autoencoder()\n",
        "a = tf.zeros((128,88))\n",
        "ae.code(a, k=10)\n",
        "\n",
        "print(a.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BA7MRaf3nrC"
      },
      "source": [
        "# This preprocesses data and creates pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dDuXiM626TA"
      },
      "source": [
        "from HT.chord_symbol_recognition_ae import train_HT\n",
        "from collections import Counter, namedtuple\n",
        "\n",
        "\n",
        "# Chord symbol recognition\n",
        "# train_BTC() # Bi-directional Transformer for Chord Recognition\n",
        "# train_CRNN() # Convolutional Recurrent Neural Network\n",
        "root_dict = {'C': 0, 'C+': 1, 'D': 2, 'D+': 3, 'E': 4, 'F': 5, 'F+': 6, 'G': 7, 'G+': 8, 'A': 9, 'A+': 10, 'B': 11, 'pad': 12}\n",
        "tquality_dict = {'M': 0, 'm': 1, 'O': 2, 'pad': 3}  # 'O' stands for 'others'\n",
        "n_chord_classes = 24 + 1  # 24 major-minor modes plus 1 others\n",
        "\n",
        "ae = autoencoder()\n",
        "# Hyperparameters\n",
        "hyperparameters = namedtuple('hyperparameters',\n",
        "                              ['dataset',\n",
        "                              'test_set_id',\n",
        "                              'graph_location',\n",
        "                              'n_root_classes',\n",
        "                              'n_tquality_classes',\n",
        "                              'n_chord_classes',\n",
        "                              'n_steps',\n",
        "                              'input_embed_size',\n",
        "                              'n_layers',\n",
        "                              'n_heads',\n",
        "                              'train_sequence_with_overlap',\n",
        "                              'initial_learning_rate',\n",
        "                              'drop',\n",
        "                              'n_batches',\n",
        "                              'n_training_steps',\n",
        "                              'n_in_succession',\n",
        "                              'annealing_rate',\n",
        "                               'autoencoder'])\n",
        "\n",
        "hp = hyperparameters(dataset='/content/', # {'BPS_FH', 'Preludes'}\n",
        "                      test_set_id=1, # {1, 2, 3, 4}\n",
        "                      graph_location='model',\n",
        "                      n_root_classes=len(root_dict.keys()),\n",
        "                      n_tquality_classes=len(tquality_dict.keys()),\n",
        "                      n_chord_classes=n_chord_classes,\n",
        "                      n_steps=128,\n",
        "                      input_embed_size=128,\n",
        "                      n_layers=2,\n",
        "                      n_heads=4,\n",
        "                      train_sequence_with_overlap=True,\n",
        "                      initial_learning_rate=1e-4,\n",
        "                      drop=0.1,\n",
        "                      n_batches=40,\n",
        "                      n_training_steps=100000,\n",
        "                      n_in_succession=10,\n",
        "                      annealing_rate=1.1,\n",
        "                      autoencoder=ae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrXxS30i3ygJ"
      },
      "source": [
        "# Make pytorch dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NJTCEIzM1Rw"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFtAeNaVNjDW"
      },
      "source": [
        "train_HT(hp, train_data, test_data2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOAc_Zu9V2e7"
      },
      "source": [
        "#test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9CkJV5MthTU"
      },
      "source": [
        "#play example from BPS dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wow3sdkl5Xdy"
      },
      "source": [
        "\n",
        "\n",
        "def piano_roll_to_pretty_midi(piano_roll, fs=8, program=0):\n",
        "    '''Convert a Piano Roll array into a PrettyMidi object\n",
        "     with a single instrument.\n",
        "    Parameters\n",
        "    ----------\n",
        "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
        "        Piano roll of one instrument\n",
        "    fs : int\n",
        "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
        "        by ``1./fs`` seconds.\n",
        "    program : int\n",
        "        The program number of the instrument.\n",
        "    Returns\n",
        "    -------\n",
        "    midi_object : pretty_midi.PrettyMIDI\n",
        "        A pretty_midi.PrettyMIDI class instance describing\n",
        "        the piano roll.\n",
        "    '''\n",
        "    notes, frames = piano_roll.shape\n",
        "    pm = pretty_midi.PrettyMIDI()\n",
        "    instrument = pretty_midi.Instrument(program=program)\n",
        "\n",
        "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
        "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
        "\n",
        "    # use changes in velocities to find note on / note off events\n",
        "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
        "\n",
        "    # keep track on velocities and note on times\n",
        "    prev_velocities = np.zeros(notes, dtype=int)\n",
        "    note_on_time = np.zeros(notes)\n",
        "\n",
        "    for time, note in zip(*velocity_changes):\n",
        "        # use time + 1 because of padding above\n",
        "        velocity = piano_roll[note, time + 1]\n",
        "        time = time / fs\n",
        "        if velocity > 0:\n",
        "            if prev_velocities[note] == 0:\n",
        "                note_on_time[note] = time\n",
        "                prev_velocities[note] = velocity\n",
        "        else:\n",
        "            pm_note = pretty_midi.Note(\n",
        "                velocity=prev_velocities[note],\n",
        "                pitch=note,\n",
        "                start=note_on_time[note],\n",
        "                end=time)\n",
        "            instrument.notes.append(pm_note)\n",
        "            prev_velocities[note] = 0\n",
        "    pm.instruments.append(instrument)\n",
        "    return pm\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTxlEUDlC_5y"
      },
      "source": [
        "import IPython.display\n",
        "index = 54 ## 44 66 & 0 & 1 500 omg 1021\n",
        "\n",
        "#lets play a batch \n",
        "pianoex = test_data[\"pianoroll\"]\n",
        "# for i,ba in enumerate(pianoex): \n",
        "#     ##print(ba[0].shape)\n",
        "#     if i < index: \n",
        "#         continue\n",
        "#     listen = i\n",
        "\n",
        "\n",
        "def pad88to128(piano_roll):\n",
        "    arr = np.zeros((128,int(piano_roll.shape[1])))\n",
        "    pad = (128 - 88)//2\n",
        "    arr[pad:(128-pad),0:arr.shape[1]] = piano_roll\n",
        "    return arr\n",
        "\n",
        "print(pianoex[index].T.shape)\n",
        "arr = pad88to128(pianoex[index].T)\n",
        "pm = piano_roll_to_pretty_midi(arr)\n",
        "IPython.display.Audio(pm.synthesize(fs=16000), rate=16000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN2XoiSO2wbm"
      },
      "source": [
        "import libfmp.c1\n",
        "score = libfmp.c1.midi_to_list(pm)\n",
        "\n",
        "libfmp.c1.visualize_piano_roll(score, figsize=(8, 3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsB6hR7-w3JR"
      },
      "source": [
        "import IPython.display\n",
        "index = 54 ## 44 66 & 0 & 1 500 omg 1021\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "#lets play a batch \n",
        "pianoex = train_data[\"pianoroll\"]\n",
        "\n",
        "def pad88to128(piano_roll):\n",
        "    arr = np.zeros((128,int(piano_roll.shape[1])))\n",
        "    pad = (128 - 88)//2\n",
        "    arr[pad:(128-pad),0:arr.shape[1]] = piano_roll\n",
        "    return arr\n",
        "\n",
        "m = np.array(pianoex[index].astype(\"float32\"))\n",
        "print(m.shape)\n",
        "model_checkpoint = '/content/mmymymymy-0'\n",
        "\n",
        "g = tf.train.import_meta_graph('/content/mmymymymy-0.meta')\n",
        "print(g)\n",
        "\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "with tf.compat.v1.Session() as sess: \n",
        "    init.run() \n",
        "    g.restore(sess, model_checkpoint)\n",
        "    out =s hp.autoencoder.code(m)\n",
        "    s = 0.5* tf.reduce_mean(tf.pow(out - m, 2))\n",
        "    np_out = sess.run(out)\n",
        "    ss = sess.run(s)\n",
        "\n",
        "print(\"MSE: \", ss)\n",
        "\n",
        "np_out = np_out.T\n",
        "\n",
        "arr = pad88to128(np_out)\n",
        "pm = piano_roll_to_pretty_midi(arr)\n",
        "IPython.display.Audio(pm.synthesize(fs=16000), rate=16000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qAXyG_NCYn4"
      },
      "source": [
        "import libfmp.c1\n",
        "score = libfmp.c1.midi_to_list(pm)\n",
        "\n",
        "libfmp.c1.visualize_piano_roll(score, figsize=(8, 3))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}